{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1.Data processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ML Libraries\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "\n",
    "columns = ['id','nb_words_title','nb_words_content','pp_uniq_words','pp_stop_words','pp_uniq_non-stop_words',\n",
    "            'nb_links','nb_outside_links','nb_images','nb_videos','ave_word_length','nb_keywords','category',\n",
    "            'nb_mina_mink','nb_mina_maxk','nb_mina_avek','nb_maxa_mink','nb_maxa_maxk','nb_maxa_avek','nb_avea_mink',\n",
    "            'nb_avea_maxk','nb_avea_avek','nb_min_linked','nb_max_linked','nb_ave_linked','weekday','dist_topic_0',\n",
    "            'dist_topic_1','dist_topic_2','dist_topic_3','dist_topic_4','subj','polar','pp_pos_words','pp_neg_words',\n",
    "            'pp_pos_words_in_nonneutral','ave_polar_pos','min_polar_pos','max_polar_pos','ave_polar_neg','min_polar_neg',\n",
    "            'max_polar_neg','subj_title','polar_title'\n",
    "          ]\n",
    "\n",
    "train_data = pd.read_csv('train.csv', delimiter =' ', names = columns)\n",
    "train_data_target = pd.read_csv('train-targets.csv')\n",
    "train_data_target = train_data_target.set_index('Id')\n",
    "validation_set = pre.scale(pd.read_csv('test-val.csv',delimiter = ' ',names=columns).set_index('id'))\n",
    "\n",
    "\n",
    "\n",
    "#test_set = pd.read_csv('test-val.csv', delimiter = ' ')\n",
    "\n",
    "\n",
    "\n",
    "util_train_data = pre.scale(train_data.drop('id', axis=1))\n",
    "util_train_data = pd.DataFrame(util_train_data, columns = columns[1:])\n",
    "\n",
    "train_data, test_set, target_train, target_test = train_test_split(\n",
    "                                                        util_train_data,\n",
    "                                                        train_data_target,\n",
    "                                                        random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_target_train =np.log(target_train['Prediction'])\n",
    "new_target_test = np.log(target_test['Prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.Evaluation Metric</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(h, y): \n",
    "    \"\"\"\n",
    "    Compute the Root Mean Squared Log Error for hypthesis h and targets y\n",
    "     \n",
    "    Args:\n",
    "        h - numpy array containing predictions with shape (n_samples, n_targets)\n",
    "        y - numpy array containing targets with shape (n_samples, n_targets)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Data mining </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "opti_rate = 0.075151515\n",
    "\n",
    "clf2 = GradientBoostingRegressor(learning_rate = opti_rate, random_state = 1)\n",
    "clf2.fit(train_data, new_target_train)\n",
    "prediction_GB = clf2.predict(test_set)\n",
    "#rmsle(new_target_test,prediction_GB) # 0.03554735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3750/3750 [==============================] - 0s 4us/step - loss: 53.0885\n",
      "Epoch 2/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 48.5212\n",
      "Epoch 3/30\n",
      "3750/3750 [==============================] - 0s 10us/step - loss: 45.3360\n",
      "Epoch 4/30\n",
      "3750/3750 [==============================] - 0s 16us/step - loss: 42.8986\n",
      "Epoch 5/30\n",
      "3750/3750 [==============================] - 0s 8us/step - loss: 40.3025\n",
      "Epoch 6/30\n",
      "3750/3750 [==============================] - 0s 9us/step - loss: 38.0471\n",
      "Epoch 7/30\n",
      "3750/3750 [==============================] - 0s 8us/step - loss: 36.1867\n",
      "Epoch 8/30\n",
      "3750/3750 [==============================] - 0s 12us/step - loss: 34.1533\n",
      "Epoch 9/30\n",
      "3750/3750 [==============================] - 0s 9us/step - loss: 31.6673\n",
      "Epoch 10/30\n",
      "3750/3750 [==============================] - 0s 13us/step - loss: 29.5875\n",
      "Epoch 11/30\n",
      "3750/3750 [==============================] - 0s 8us/step - loss: 27.7468\n",
      "Epoch 12/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 25.9771\n",
      "Epoch 13/30\n",
      "3750/3750 [==============================] - 0s 9us/step - loss: 24.5712\n",
      "Epoch 14/30\n",
      "3750/3750 [==============================] - 0s 9us/step - loss: 23.0856\n",
      "Epoch 15/30\n",
      "3750/3750 [==============================] - 0s 6us/step - loss: 21.1453\n",
      "Epoch 16/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 20.7306\n",
      "Epoch 17/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 20.0161\n",
      "Epoch 18/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 18.1867\n",
      "Epoch 19/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 17.6299\n",
      "Epoch 20/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 16.3637\n",
      "Epoch 21/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 16.4316\n",
      "Epoch 22/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 15.5277\n",
      "Epoch 23/30\n",
      "3750/3750 [==============================] - 0s 8us/step - loss: 14.9949\n",
      "Epoch 24/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 15.2969\n",
      "Epoch 25/30\n",
      "3750/3750 [==============================] - 0s 6us/step - loss: 14.5047\n",
      "Epoch 26/30\n",
      "3750/3750 [==============================] - 0s 6us/step - loss: 14.3454\n",
      "Epoch 27/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 13.4507\n",
      "Epoch 28/30\n",
      "3750/3750 [==============================] - 0s 7us/step - loss: 14.0986\n",
      "Epoch 29/30\n",
      "3750/3750 [==============================] - 0s 6us/step - loss: 14.5250\n",
      "Epoch 30/30\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 13.13 - 0s 7us/step - loss: 13.1765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x175450b8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape= (43,)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu',name= 'good_layer'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "\n",
    "\n",
    "model.fit(np.array(train_data),new_target_train, epochs = 30, batch_size=1000)\n",
    "#prediction_NN = model.predict(np.array(test_set))\n",
    "#rmsle(np.array(new_target_test),prediction_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_add = Model(inputs = model.input,\n",
    "                  outputs = model.get_layer(\"good_layer\").output)\n",
    "\n",
    "model_add.compile(loss = 'mse', optimizer = 'rmsprop')\n",
    "\n",
    "output_neural = model_add.predict(np.array(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750L, 20L)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdherbemont\\AppData\\Local\\Continuum\\Anaconda2\\envs\\Python27\\lib\\site-packages\\lightgbm\\basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "C:\\Users\\vdherbemont\\AppData\\Local\\Continuum\\Anaconda2\\envs\\Python27\\lib\\site-packages\\lightgbm\\basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', colsample_bytree=1.0, learning_rate=0.1,\n",
       "       max_bin=255, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=10,\n",
       "       n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm\n",
    "clf1 = lightgbm.LGBMRegressor()\n",
    "\n",
    "clf1.fit(output_neural, np.array(target_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0511300719284979"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pipe pour test\n",
    "\n",
    "def pipe_kaggle(data_set, target = None):\n",
    "    neural_results = model_add.predict(np.array(data_set))\n",
    "    prediction = clf1.predict(neural_results)\n",
    "    if target is None:\n",
    "        return(prediction)\n",
    "    else:\n",
    "        return(np.sqrt(np.square(np.log(prediction + 1) - np.log(target + 1)).mean()))\n",
    "\n",
    "pipe_kaggle(test_set,target = np.array(target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe_kaggle(validation_set)\n",
    "\n",
    "(pd.DataFrame((np.round(results)).astype('int'))).to_csv('results.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgboost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-470db3bed040>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m clf1 = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n\u001b[0m\u001b[0;32m      2\u001b[0m                            colsample_bytree=1, max_depth=7)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgboost' is not defined"
     ]
    }
   ],
   "source": [
    "clf1 = xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
